"""
üéØ ACBE-S73 QUANTUM BETTING SUITE v2.0
Sistema profesional de optimizaci√≥n de portafolios de apuestas deportivas
Combina Inferencia Bayesiana Gamma-Poisson, Teor√≠a de la Informaci√≥n y Criterio de Kelly
Con cobertura S73 completa (2 errores) y gesti√≥n probabil√≠stica avanzada
Autor: Arquitecto de Software & Data Scientist Senior
"""

import streamlit as st
import numpy as np
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
from typing import List, Tuple, Dict, Optional
warnings.filterwarnings('ignore')

# ============================================================================
# SECCI√ìN 1: CONFIGURACI√ìN DEL SISTEMA Y CONSTANTES MATEM√ÅTICAS
# ============================================================================

class SystemConfig:
    """Configuraci√≥n centralizada del sistema ACBE-S73."""
    
    # Par√°metros de simulaci√≥n
    MONTE_CARLO_ITERATIONS = 10000
    KELLY_FRACTION_MAX = 0.03  # 3% m√°ximo por columna
    MIN_PROBABILITY = 1e-10    # Evitar log(0)
    BASE_ENTROPY = 3           # Base logar√≠tmica para 3 resultados
    
    # Modelo Bayesiano Gamma-Poisson
    DEFAULT_ATTACK_MEAN = 1.2
    DEFAULT_DEFENSE_MEAN = 0.8
    DEFAULT_HOME_ADVANTAGE = 1.1
    DEFAULT_ALPHA_PRIOR = 2.0  # Par√°metro de forma Gamma
    DEFAULT_BETA_PRIOR = 1.0   # Par√°metro de tasa Gamma
    
    # Sistema S73
    NUM_MATCHES = 6            # Partidos por sistema
    FULL_COMBINATIONS = 3 ** 6  # 729 combinaciones posibles
    TARGET_COMBINATIONS = 73   # Objetivo de columnas reducidas
    HAMMING_DISTANCE_TARGET = 2  # ¬°CORREGIDO: Cobertura de 2 errores!
    
    # Umbrales de clasificaci√≥n por entrop√≠a
    STRONG_MATCH_THRESHOLD = 0.30   # ‚â§ 0.30: Partido Fuerte (1 signo)
    MEDIUM_MATCH_THRESHOLD = 0.60   # 0.30-0.60: Partido Medio (2 signos)
                                    # ‚â• 0.60: Partido Ca√≥tico (3 signos)
    
    # Gesti√≥n de riesgo
    MIN_ODDS = 1.01
    MAX_ODDS = 100.0
    DEFAULT_BANKROLL = 10000.0
    MAX_PORTFOLIO_EXPOSURE = 0.15   # 15% exposici√≥n m√°xima del portafolio
    MIN_JOINT_PROBABILITY = 0.001   # Umbral m√≠nimo probabilidad conjunta
    
    # Configuraci√≥n visual
    COLORS = {
        'primary': '#1E88E5',
        'secondary': '#FFC107', 
        'success': '#4CAF50',
        'danger': '#F44336',
        'warning': '#FF9800',
        'info': '#00BCD4'
    }
    
    # Mapeo de resultados
    OUTCOME_MAPPING = {'1': 0, 'X': 1, '2': 2}
    OUTCOME_LABELS = ['1', 'X', '2']
    OUTCOME_COLORS = ['#1E88E5', '#FF9800', '#F44336']

# ============================================================================
# SECCI√ìN 2: MODELO MATEM√ÅTICO ACBE (VECTORIZADO)
# ============================================================================

class ACBEModel:
    """Modelo Bayesiano Gamma-Poisson para estimaci√≥n de probabilidades."""
    
    @staticmethod
    @st.cache_data
    def vectorized_poisson_simulation(lambda_home: np.ndarray, 
                                     lambda_away: np.ndarray, 
                                     n_sims: int = SystemConfig.MONTE_CARLO_ITERATIONS) -> np.ndarray:
        """
        Simulaci√≥n vectorizada de resultados usando distribuci√≥n Poisson.
        
        Args:
            lambda_home: Tasas de goles locales (n_matches,)
            lambda_away: Tasas de goles visitantes (n_matches,)
            n_sims: Iteraciones Monte Carlo
            
        Returns:
            Array (n_matches, 3) con probabilidades [P(1), P(X), P(2)]
        """
        n_matches = len(lambda_home)
        
        # Generaci√≥n vectorizada de goles
        home_goals = np.random.poisson(
            lam=np.tile(lambda_home, (n_sims, 1)),
            size=(n_sims, n_matches)
        )
        
        away_goals = np.random.poisson(
            lam=np.tile(lambda_away, (n_sims, 1)),
            size=(n_sims, n_matches)
        )
        
        # C√°lculo de resultados (vectorizado)
        home_wins = (home_goals > away_goals).sum(axis=0) / n_sims
        draws = (home_goals == away_goals).sum(axis=0) / n_sims
        away_wins = (home_goals < away_goals).sum(axis=0) / n_sims
        
        # Ensamblar matriz de probabilidades
        probabilities = np.column_stack([home_wins, draws, away_wins])
        
        # Normalizaci√≥n y estabilidad num√©rica
        probabilities = np.clip(probabilities, SystemConfig.MIN_PROBABILITY, 1.0)
        probabilities = probabilities / probabilities.sum(axis=1, keepdims=True)
        
        return probabilities
    
    @staticmethod
    @st.cache_data
    def gamma_poisson_bayesian(attack_strengths: np.ndarray,
                              defense_strengths: np.ndarray,
                              home_advantage: float = SystemConfig.DEFAULT_HOME_ADVANTAGE,
                              alpha_prior: float = SystemConfig.DEFAULT_ALPHA_PRIOR,
                              beta_prior: float = SystemConfig.DEFAULT_BETA_PRIOR) -> Tuple[np.ndarray, np.ndarray]:
        """
        Modelo Bayesian Gamma-Poisson para estimar tasas de goles.
        
        Args:
            attack_strengths: Array (n_matches, 2) [ataque_local, ataque_visitante]
            defense_strengths: Array (n_matches, 2) [defensa_local, defensa_visitante]
            home_advantage: Ventaja de local
            
        Returns:
            lambda_home, lambda_away: Tasas estimadas de goles
        """
        n_matches = attack_strengths.shape[0]
        
        # C√°lculo de lambda con ventaja local
        lambda_home = attack_strengths[:, 0] * defense_strengths[:, 1] * home_advantage
        lambda_away = attack_strengths[:, 1] * defense_strengths[:, 0]
        
        # Actualizaci√≥n Bayesian (Gamma-Poisson conjugada)
        alpha_posterior = alpha_prior + lambda_home + lambda_away
        beta_posterior = beta_prior + 2  # 2 equipos por partido
        
        # Muestreo de la posterior (vectorizado)
        lambda_home_samples = np.random.gamma(
            shape=alpha_posterior,
            scale=1/beta_posterior,
            size=(SystemConfig.MONTE_CARLO_ITERATIONS, n_matches)
        ).mean(axis=0)
        
        lambda_away_samples = np.random.gamma(
            shape=alpha_posterior,
            scale=1/beta_posterior,
            size=(SystemConfig.MONTE_CARLO_ITERATIONS, n_matches)
        ).mean(axis=0)
        
        return lambda_home_samples, lambda_away_samples
    
    @staticmethod
    def calculate_entropy(probabilities: np.ndarray) -> np.ndarray:
        """
        Calcula entrop√≠a de Shannon (base 3) para cada partido.
        
        Args:
            probabilities: Array (n_matches, 3) de probabilidades
            
        Returns:
            Array (n_matches,) de entrop√≠as
        """
        # Estabilidad num√©rica
        probs = np.clip(probabilities, SystemConfig.MIN_PROBABILITY, 1.0)
        
        # Entrop√≠a vectorizada (base 3)
        entropy = -np.sum(probs * np.log(probs) / np.log(SystemConfig.BASE_ENTROPY), axis=1)
        
        return entropy
    
    @staticmethod
    def normalize_entropy(entropy: np.ndarray) -> np.ndarray:
        """
        Normaliza entrop√≠as al rango [0, 1].
        
        Args:
            entropy: Array de entrop√≠as
            
        Returns:
            Array normalizado
        """
        if np.max(entropy) - np.min(entropy) < SystemConfig.MIN_PROBABILITY:
            return np.ones_like(entropy)
        
        return (entropy - np.min(entropy)) / (np.max(entropy) - np.min(entropy))

# ============================================================================
# SECCI√ìN 3: TEOR√çA DE LA INFORMACI√ìN Y CLASIFICACI√ìN PROBABIL√çSTICA
# ============================================================================

class InformationTheory:
    """Clasificaci√≥n probabil√≠stica basada en entrop√≠a y teor√≠a de informaci√≥n."""
    
    @staticmethod
    def classify_matches_by_entropy(probabilities: np.ndarray, 
                                   normalized_entropies: np.ndarray) -> Tuple[List[List[int]], List[str]]:
        """
        Clasifica partidos seg√∫n entrop√≠a normalizada y reduce espacio de signos.
        
        Sistema de clasificaci√≥n:
        - Entrop√≠a ‚â§ 0.30: Partido Fuerte ‚Üí 1 signo (el m√°s probable)
        - Entrop√≠a 0.30-0.60: Partido Medio ‚Üí 2 signos (m√°s probables)
        - Entrop√≠a ‚â• 0.60: Partido Ca√≥tico ‚Üí 3 signos
        
        Args:
            probabilities: Array (n_matches, 3) de probabilidades
            normalized_entropies: Array (n_matches,) de entrop√≠as normalizadas
            
        Returns:
            allowed_signs: Lista de listas con signos permitidos por partido
            classifications: Lista de clasificaciones
        """
        allowed_signs = []
        classifications = []
        
        for i in range(len(probabilities)):
            entropy_norm = normalized_entropies[i]
            
            if entropy_norm <= SystemConfig.STRONG_MATCH_THRESHOLD:
                # Partido Fuerte: solo el signo m√°s probable
                best_sign = np.argmax(probabilities[i])
                allowed_signs.append([best_sign])
                classifications.append('Fuerte')
                
            elif entropy_norm <= SystemConfig.MEDIUM_MATCH_THRESHOLD:
                # Partido Medio: 2 signos m√°s probables
                top_two = np.argsort(probabilities[i])[-2:].tolist()
                allowed_signs.append(top_two)
                classifications.append('Medio')
                
            else:
                # Partido Ca√≥tico: 3 signos
                allowed_signs.append([0, 1, 2])
                classifications.append('Ca√≥tico')
        
        return allowed_signs, classifications
    
    @staticmethod
    def calculate_expected_value(probabilities: np.ndarray, odds_matrix: np.ndarray) -> np.ndarray:
        """
        Calcula el valor esperado (EV) para cada apuesta.
        
        F√≥rmula: EV = p * q - 1, donde:
        - p: probabilidad estimada
        - q: cuota ofrecida
        
        Args:
            probabilities: Array (n_matches, 3) de probabilidades
            odds_matrix: Array (n_matches, 3) de cuotas
            
        Returns:
            Array (n_matches, 3) de valores esperados
        """
        return probabilities * odds_matrix - 1

# ============================================================================
# SECCI√ìN 4: SISTEMA COMBINATORIO S73 (COBERTURA DE 2 ERRORES)
# ============================================================================

class S73System:
    """Sistema combinatorio S73 con cobertura garantizada de 2 errores."""
    
    @staticmethod
    @st.cache_data
    def generate_prefiltered_combinations(probabilities: np.ndarray,
                                         normalized_entropies: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        Genera combinaciones pre-filtradas usando clasificaci√≥n por entrop√≠a.
        
        Reduce el espacio de b√∫squeda antes de aplicar el sistema S73.
        
        Args:
            probabilities: Array (6, 3) de probabilidades (para 6 partidos)
            normalized_entropies: Array (6,) de entrop√≠as normalizadas
            
        Returns:
            combinations: Array (n_combinations, 6) de combinaciones filtradas
            joint_probs: Array (n_combinations,) de probabilidades conjuntas
        """
        # 1. Clasificar partidos y obtener signos permitidos
        allowed_signs, _ = InformationTheory.classify_matches_by_entropy(
            probabilities, normalized_entropies
        )
        
        # 2. Generar producto cartesiano de signos permitidos
        import itertools
        combinations_list = list(itertools.product(*allowed_signs))
        combinations = np.array(combinations_list)
        
        # 3. Calcular probabilidades conjuntas (vectorizado)
        n_combinations = len(combinations)
        joint_probs = np.ones(n_combinations)
        
        for idx, combo in enumerate(combinations):
            for match_idx, sign in enumerate(combo):
                joint_probs[idx] *= probabilities[match_idx, sign]
        
        # 4. Filtrar por umbral m√≠nimo de probabilidad conjunta
        mask = joint_probs >= SystemConfig.MIN_JOINT_PROBABILITY
        filtered_combinations = combinations[mask]
        filtered_probs = joint_probs[mask]
        
        return filtered_combinations, filtered_probs
    
    @staticmethod
    def hamming_distance_matrix(combinations: np.ndarray) -> np.ndarray:
        """
        Calcula matriz de distancias de Hamming entre combinaciones.
        
        Args:
            combinations: Array (n_combinations, 6) de combinaciones
            
        Returns:
            Array (n_combinations, n_combinations) de distancias
        """
        n = len(combinations)
        distances = np.zeros((n, n), dtype=np.int8)
        
        # C√°lculo eficiente de distancias Hamming
        for i in range(n):
            for j in range(i+1, n):
                dist = np.sum(combinations[i] != combinations[j])
                distances[i, j] = dist
                distances[j, i] = dist
        
        return distances
    
    @staticmethod
    @st.cache_data
    def build_s73_coverage_system(filtered_combinations: np.ndarray,
                                 filtered_probs: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        Construye sistema S73 con cobertura garantizada de 2 errores.
        
        Implementa algoritmo greedy optimizado que selecciona combinaciones
        que maximizan la cobertura de espacio (Hamming distance ‚â§ 2).
        
        Args:
            filtered_combinations: Combinaciones pre-filtradas
            filtered_probs: Probabilidades conjuntas correspondientes
            
        Returns:
            selected_combinations: Array de combinaciones seleccionadas
            selected_probs: Array de probabilidades seleccionadas
        """
        n_combinations = len(filtered_combinations)
        
        if n_combinations <= SystemConfig.TARGET_COMBINATIONS:
            return filtered_combinations, filtered_probs
        
        # 1. Ordenar por probabilidad descendente
        sorted_indices = np.argsort(filtered_probs)[::-1]
        sorted_combinations = filtered_combinations[sorted_indices]
        sorted_probs = filtered_probs[sorted_indices]
        
        # 2. Precalcular matriz de distancias Hamming
        distance_matrix = S73System.hamming_distance_matrix(sorted_combinations)
        
        # 3. Algoritmo greedy con cobertura de 2 errores
        selected_indices = []
        covered_indices = set()
        
        while (len(selected_indices) < SystemConfig.TARGET_COMBINATIONS and 
               len(covered_indices) < n_combinations):
            
            best_idx = -1
            best_coverage_gain = -1
            
            # Buscar combinaci√≥n que maximice cobertura de no cubiertos
            for i in range(n_combinations):
                if i in selected_indices:
                    continue
                
                # Combinaciones cubiertas por i (Hamming ‚â§ 2)
                coverage_mask = distance_matrix[i] <= SystemConfig.HAMMING_DISTANCE_TARGET
                uncovered_coverage = sum(1 for j in range(n_combinations) 
                                       if coverage_mask[j] and j not in covered_indices)
                
                # Ponderar por probabilidad y cobertura
                coverage_gain = uncovered_coverage * (1 + sorted_probs[i])
                
                if coverage_gain > best_coverage_gain:
                    best_coverage_gain = coverage_gain
                    best_idx = i
            
            if best_idx == -1:
                break
            
            # Agregar combinaci√≥n seleccionada
            selected_indices.append(best_idx)
            
            # Actualizar conjunto de combinaciones cubiertas
            newly_covered = np.where(
                distance_matrix[best_idx] <= SystemConfig.HAMMING_DISTANCE_TARGET
            )[0]
            covered_indices.update(newly_covered)
        
        # 4. Si no alcanza el target, completar con m√°s probables
        if len(selected_indices) < SystemConfig.TARGET_COMBINATIONS:
            remaining_needed = SystemConfig.TARGET_COMBINATIONS - len(selected_indices)
            for i in range(n_combinations):
                if i not in selected_indices:
                    selected_indices.append(i)
                    remaining_needed -= 1
                    if remaining_needed == 0:
                        break
        
        # 5. Extraer combinaciones seleccionadas
        selected_combinations = sorted_combinations[selected_indices]
        selected_probs = sorted_probs[selected_indices]
        
        return selected_combinations, selected_probs
    
    @staticmethod
    def calculate_combination_odds(combination: np.ndarray, odds_matrix: np.ndarray) -> float:
        """
        Calcula la cuota conjunta de una combinaci√≥n.
        
        Args:
            combination: Array (6,) con signos seleccionados
            odds_matrix: Array (6, 3) de cuotas
            
        Returns:
            Cuota conjunta (producto de cuotas seleccionadas)
        """
        selected_odds = odds_matrix[np.arange(6), combination]
        return np.prod(selected_odds)

# ============================================================================
# SECCI√ìN 5: CRITERIO DE KELLY INTEGRADO Y GESTI√ìN DE CAPITAL
# ============================================================================

class KellyCapitalManagement:
    """Gesti√≥n de capital basada en criterio de Kelly con ajustes por entrop√≠a."""
    
    @staticmethod
    def calculate_kelly_stakes(probabilities: np.ndarray,
                              odds_matrix: np.ndarray,
                              normalized_entropies: np.ndarray,
                              kelly_fraction: float = 1.0) -> np.ndarray:
        """
        Calcula stakes Kelly ajustados por entrop√≠a.
        
        F√≥rmula Kelly: f = (p*q - 1) / (q - 1)
        Ajuste por entrop√≠a: f_adj = f * (1 - H) * kelly_fraction
        
        Args:
            probabilities: Array (n_matches, 3) de probabilidades
            odds_matrix: Array (n_matches, 3) de cuotas
            normalized_entropies: Array (n_matches,) de entrop√≠as normalizadas
            kelly_fraction: Fracci√≥n de Kelly a aplicar (0-1)
            
        Returns:
            Array (n_matches, 3) de stakes recomendados
        """
        # Calcular Kelly crudo
        with np.errstate(divide='ignore', invalid='ignore'):
            kelly_raw = (probabilities * odds_matrix - 1) / (odds_matrix - 1)
        
        # Manejar casos especiales
        kelly_raw = np.nan_to_num(kelly_raw, nan=0.0, posinf=0.0, neginf=0.0)
        
        # Aplicar l√≠mites (0 a KELLY_FRACTION_MAX)
        kelly_capped = np.clip(kelly_raw, 0, SystemConfig.KELLY_FRACTION_MAX)
        
        # Ajustar por entrop√≠a (m√°s incertidumbre ‚Üí menor stake)
        entropy_adjustment = (1.0 - normalized_entropies[:, np.newaxis])
        stakes = kelly_capped * entropy_adjustment * kelly_fraction
        
        return stakes
    
    @staticmethod
    def calculate_column_kelly(combination: np.ndarray,
                              joint_probability: float,
                              combination_odds: float,
                              avg_entropy: float) -> float:
        """
        Calcula stake Kelly para una columna del sistema S73.
        
        Args:
            combination: Array (6,) de signos
            joint_probability: Probabilidad conjunta de la combinaci√≥n
            combination_odds: Cuota conjunta
            avg_entropy: Entrop√≠a promedio de la combinaci√≥n
            
        Returns:
            Stake Kelly ajustado (porcentaje del bankroll)
        """
        if combination_odds <= 1.0:
            return 0.0
        
        # Kelly para la combinaci√≥n
        kelly_raw = (joint_probability * combination_odds - 1) / (combination_odds - 1)
        
        # Aplicar l√≠mites y ajuste por entrop√≠a
        kelly_capped = max(0.0, min(kelly_raw, SystemConfig.KELLY_FRACTION_MAX))
        kelly_adjusted = kelly_capped * (1.0 - avg_entropy)
        
        return kelly_adjusted
    
    @staticmethod
    def normalize_portfolio_stakes(stakes_array: np.ndarray,
                                  max_exposure: float = SystemConfig.MAX_PORTFOLIO_EXPOSURE) -> np.ndarray:
        """
        Normaliza stakes para limitar exposici√≥n total del portafolio.
        
        Args:
            stakes_array: Array de stakes individuales
            max_exposure: Exposici√≥n m√°xima permitida (ej: 0.15 = 15%)
            
        Returns:
            Array de stakes normalizados
        """
        total_exposure = np.sum(stakes_array)
        
        if total_exposure > max_exposure:
            # Escalar proporcionalmente para respetar l√≠mite
            scaling_factor = max_exposure / total_exposure
            stakes_array = stakes_array * scaling_factor
        
        return stakes_array

# ============================================================================
# SECCI√ìN 6: MOTOR DE BACKTESTING VECTORIZADO
# ============================================================================

class VectorizedBacktester:
    """Motor de backtesting completamente vectorizado con gesti√≥n real de capital."""
    
    def __init__(self, initial_bankroll: float = SystemConfig.DEFAULT_BANKROLL):
        self.initial_bankroll = initial_bankroll
        self.bankroll = initial_bankroll
        self.equity_curve = [initial_bankroll]
        self.drawdown_curve = [0.0]
    
    @staticmethod
    @st.cache_data
    def simulate_match_outcomes(probabilities: np.ndarray, n_sims: int) -> np.ndarray:
        """
        Simula resultados de partidos usando distribuci√≥n multinomial.
        
        Args:
            probabilities: Array (n_matches, 3) de probabilidades
            n_sims: N√∫mero de simulaciones
            
        Returns:
            Array (n_sims, n_matches) de resultados (0, 1, 2)
        """
        n_matches = probabilities.shape[0]
        outcomes = np.zeros((n_sims, n_matches), dtype=int)
        
        for i in range(n_matches):
            # Muestreo multinomial vectorizado
            samples = np.random.multinomial(1, probabilities[i], size=n_sims)
            outcomes[:, i] = np.argmax(samples, axis=1)
        
        return outcomes
    
    def calculate_column_performance(self,
                                    real_outcomes: np.ndarray,
                                    combinations: np.ndarray,
                                    odds_matrix: np.ndarray,
                                    stakes_array: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        Calcula rendimiento de columnas con stakes reales.
        
        Args:
            real_outcomes: Resultados simulados (n_sims, 6)
            combinations: Combinaciones del sistema (n_columns, 6)
            odds_matrix: Cuotas (6, 3)
            stakes_array: Stakes por columna (n_columns,)
            
        Returns:
            total_returns: Retornos totales por simulaci√≥n
            column_returns: Retornos por columna (n_sims, n_columns)
        """
        n_sims, n_matches = real_outcomes.shape
        n_columns = len(combinations)
        
        # Inicializar matriz de retornos
        column_returns = np.zeros((n_sims, n_columns))
        
        # Calcular cuotas conjuntas por columna
        combination_odds = np.zeros(n_columns)
        for i, combo in enumerate(combinations):
            combination_odds[i] = S73System.calculate_combination_odds(combo, odds_matrix)
        
        # Calcular stakes en euros
        stakes_euros = stakes_array * self.bankroll
        
        # Vectorizar comparaci√≥n de resultados
        for col_idx, combination in enumerate(combinations):
            # Verificar aciertos (True si todos los partidos coinciden)
            hits = np.all(real_outcomes == combination, axis=1)
            
            # Calcular retorno: ganancia si acierta, p√©rdida stake si falla
            column_returns[:, col_idx] = np.where(
                hits,
                stakes_euros[col_idx] * (combination_odds[col_idx] - 1),  # Ganancia
                -stakes_euros[col_idx]                                   # P√©rdida
            )
        
        # Retorno total por simulaci√≥n (suma de todas las columnas)
        total_returns = column_returns.sum(axis=1)
        
        return total_returns, column_returns
    
    def run_backtest(self,
                    probabilities: np.ndarray,
                    odds_matrix: np.ndarray,
                    normalized_entropies: np.ndarray,
                    s73_results: Dict,
                    n_rounds: int = 100,
                    n_sims_per_round: int = 1000,
                    kelly_fraction: float = 0.5) -> Dict:
        """
        Ejecuta backtesting completo con gesti√≥n realista de capital.
        
        Args:
            probabilities: Probabilidades ACBE (6, 3)
            odds_matrix: Cuotas (6, 3)
            normalized_entropies: Entrop√≠as normalizadas (6,)
            s73_results: Resultados del sistema S73
            n_rounds: N√∫mero de rondas/jornadas
            n_sims_per_round: Simulaciones Monte Carlo por ronda
            kelly_fraction: Fracci√≥n conservadora de Kelly
            
        Returns:
            Diccionario con resultados del backtest
        """
        combinations = s73_results['combinations']
        n_columns = len(combinations)
        
        # Reinicializar m√©tricas
        self.bankroll = self.initial_bankroll
        self.equity_curve = [self.bankroll]
        self.drawdown_curve = [0.0]
        
        all_returns = []
        round_metrics = []
        
        for round_idx in range(n_rounds):
            # 1. Simular resultados reales
            real_outcomes = self.simulate_match_outcomes(probabilities, n_sims_per_round)
            
            # 2. Calcular stakes actualizados (pueden cambiar con bankroll)
            current_stakes = self._calculate_current_stakes(
                s73_results, kelly_fraction
            )
            
            # 3. Calcular rendimiento
            round_returns, column_returns = self.calculate_column_performance(
                real_outcomes, combinations, odds_matrix, current_stakes
            )
            
            # 4. Actualizar bankroll (usar retorno promedio esperado)
            avg_return = np.mean(round_returns)
            self.bankroll += avg_return
            
            # 5. Registrar m√©tricas
            self.equity_curve.append(self.bankroll)
            all_returns.extend(round_returns)
            
            # Calcular drawdown actual
            peak = np.max(self.equity_curve)
            current_dd = (peak - self.bankroll) / peak * 100 if peak > 0 else 0
            self.drawdown_curve.append(current_dd)
            
            # M√©tricas de la ronda
            round_metrics.append({
                'round': round_idx + 1,
                'bankroll': self.bankroll,
                'avg_return': avg_return,
                'std_return': np.std(round_returns),
                'win_rate': np.mean(round_returns > 0) * 100,
                'max_single_return': np.max(round_returns),
                'min_single_return': np.min(round_returns)
            })
        
        # Calcular m√©tricas finales
        final_metrics = self._calculate_final_metrics(all_returns, n_rounds)
        
        return {
            'equity_curve': np.array(self.equity_curve),
            'drawdown_curve': np.array(self.drawdown_curve),
            'final_metrics': final_metrics,
            'round_metrics': round_metrics,
            'all_returns': np.array(all_returns)
        }
    
    def _calculate_current_stakes(self, s73_results: Dict, kelly_fraction: float) -> np.ndarray:
        """Calcula stakes actualizados basados en bankroll actual."""
        stakes = s73_results['kelly_stakes'].copy()
        
        # Ajustar por fracci√≥n de Kelly conservadora
        stakes = stakes * kelly_fraction
        
        # Normalizar para limitar exposici√≥n total
        stakes = KellyCapitalManagement.normalize_portfolio_stakes(stakes)
        
        return stakes
    
    def _calculate_final_metrics(self, all_returns: List[float], n_rounds: int) -> Dict:
        """Calcula m√©tricas finales agregadas del backtest."""
        returns_array = np.array(all_returns)
        
        # ROI y retorno total
        total_return = self.bankroll - self.initial_bankroll
        total_return_pct = (total_return / self.initial_bankroll) * 100
        
        # Sharpe Ratio (tasa libre de riesgo = 0)
        if np.std(returns_array) > 0:
            sharpe_ratio = (np.mean(returns_array) / np.std(returns_array)) * np.sqrt(252)
        else:
            sharpe_ratio = 0.0
        
        # Drawdown m√°ximo
        max_drawdown = np.max(self.drawdown_curve)
        
        # CAGR (Compound Annual Growth Rate)
        if self.bankroll > 0:
            cagr = ((self.bankroll / self.initial_bankroll) ** (252 / n_rounds) - 1) * 100
        else:
            cagr = -100.0
        
        # Value at Risk (VaR 95%)
        var_95 = np.percentile(returns_array, 5) if len(returns_array) > 0 else 0
        
        # Win rate y estad√≠sticas
        positive_returns = returns_array[returns_array > 0]
        negative_returns = returns_array[returns_array <= 0]
        
        win_rate = (len(positive_returns) / len(returns_array) * 100) if len(returns_array) > 0 else 0
        avg_win = np.mean(positive_returns) if len(positive_returns) > 0 else 0
        avg_loss = np.mean(negative_returns) if len(negative_returns) > 0 else 0
        
        # Profit factor
        if np.sum(negative_returns) < 0:
            profit_factor = abs(np.sum(positive_returns) / np.sum(negative_returns))
        else:
            profit_factor = 0.0
        
        # Probabilidad de ruina (bankroll < 50% inicial)
        ruin_prob = np.mean(np.array(self.equity_curve) < self.initial_bankroll * 0.5) * 100
        
        return {
            'initial_bankroll': self.initial_bankroll,
            'final_bankroll': self.bankroll,
            'total_return': total_return,
            'total_return_pct': total_return_pct,
            'roi_per_round': (np.mean(returns_array) / self.initial_bankroll) * 100,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'cagr': cagr,
            'var_95': var_95,
            'win_rate': win_rate,
            'profit_factor': profit_factor,
            'avg_win': avg_win,
            'avg_loss': avg_loss,
            'ruin_probability': ruin_prob,
            'std_returns': np.std(returns_array) if len(returns_array) > 0 else 0
        }

# ============================================================================
# SECCI√ìN 7: GENERADOR DE DATOS SINT√âTICOS
# ============================================================================

class SyntheticDataGenerator:
    """Genera datos sint√©ticos realistas para pruebas del sistema."""
    
    @staticmethod
    @st.cache_data
    def generate_complete_dataset(n_matches: int = 6, seed: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame, np.ndarray]:
        """
        Genera dataset sint√©tico completo con par√°metros realistas.
        
        Args:
            n_matches: N√∫mero de partidos a generar
            seed: Semilla para reproducibilidad
            
        Returns:
            matches_df: DataFrame con par√°metros de equipos
            odds_df: DataFrame con cuotas
            probabilities: Array (n_matches, 3) de probabilidades reales
        """
        np.random.seed(seed)
        
        # Par√°metros de equipos (distribuci√≥n Beta para mayor realismo)
        attack_strengths = np.random.beta(a=2, b=2, size=(n_matches, 2)) * 1.5 + 0.5
        defense_strengths = np.random.beta(a=2, b=2, size=(n_matches, 2)) * 1.2 + 0.4
        
        # Ventaja local variable
        home_advantages = np.random.uniform(1.05, 1.25, n_matches)
        
        # Estimaci√≥n bayesiana de tasas de goles
        lambda_home = np.zeros(n_matches)
        lambda_away = np.zeros(n_matches)
        
        for i in range(n_matches):
            lambda_home[i] = attack_strengths[i, 0] * defense_strengths[i, 1] * home_advantages[i]
            lambda_away[i] = attack_strengths[i, 1] * defense_strengths[i, 0]
        
        # Simulaci√≥n de probabilidades reales
        probabilities = ACBEModel.vectorized_poisson_simulation(lambda_home, lambda_away)
        
        # Generar cuotas con m√°rgenes variables (realismo de casa de apuestas)
        margins = np.random.uniform(0.03, 0.07, n_matches)  # 3-7% de margen
        odds = np.zeros((n_matches, 3))
        
        for i in range(n_matches):
            odds[i] = 1 / (probabilities[i] * (1 + margins[i]))
            odds[i] = np.clip(odds[i], SystemConfig.MIN_ODDS, SystemConfig.MAX_ODDS)
        
        # Crear DataFrames
        matches_df = pd.DataFrame({
            'match_id': range(1, n_matches + 1),
            'home_attack': attack_strengths[:, 0],
            'away_attack': attack_strengths[:, 1],
            'home_defense': defense_strengths[:, 0],
            'away_defense': defense_strengths[:, 1],
            'home_advantage': home_advantages,
            'lambda_home': lambda_home,
            'lambda_away': lambda_away
        })
        
        odds_df = pd.DataFrame(
            odds,
            columns=['odds_1', 'odds_X', 'odds_2']
        )
        odds_df.index = range(1, n_matches + 1)
        
        return matches_df, odds_df, probabilities

# ============================================================================
# SECCI√ìN 8: INTERFAZ STREAMLIT PROFESIONAL
# ============================================================================

class ACBEApp:
    """Interfaz principal de la aplicaci√≥n Streamlit."""
    
    def __init__(self):
        self.setup_page_config()
    
    def setup_page_config(self):
        """Configuraci√≥n de la p√°gina Streamlit."""
        st.set_page_config(
            page_title="ACBE-S73 Quantum Betting Suite v2.0",
            page_icon="üéØ",
            layout="wide",
            initial_sidebar_state="expanded"
        )
    
    def render_sidebar(self) -> Dict:
        """Renderiza sidebar y retorna configuraci√≥n del usuario."""
        with st.sidebar:
            st.header("‚öôÔ∏è Configuraci√≥n del Sistema")
            
            # Bankroll inicial
            bankroll = st.number_input(
                "Bankroll Inicial (‚Ç¨)",
                min_value=100.0,
                max_value=1000000.0,
                value=SystemConfig.DEFAULT_BANKROLL,
                step=1000.0,
                help="Capital inicial para simulaciones"
            )
            
            # Par√°metros de riesgo
            st.subheader("üìä Gesti√≥n de Riesgo")
            
            kelly_fraction = st.slider(
                "Fracci√≥n de Kelly",
                min_value=0.1,
                max_value=1.0,
                value=0.5,
                step=0.1,
                help="Fracci√≥n conservadora del Kelly completo"
            )
            
            max_exposure = st.slider(
                "Exposici√≥n M√°xima (%)",
                min_value=5,
                max_value=30,
                value=15,
                step=1,
                help="Porcentaje m√°ximo del bankroll en apuestas"
            )
            
            # Configuraci√≥n de simulaciones
            st.subheader("üé≤ Par√°metros de Simulaci√≥n")
            
            monte_carlo_sims = st.number_input(
                "Simulaciones por Ronda",
                min_value=1000,
                max_value=50000,
                value=1000,
                step=1000
            )
            
            n_rounds = st.slider(
                "Rondas de Backtesting",
                min_value=10,
                max_value=500,
                value=100,
                step=10
            )
            
            # Fuente de datos
            st.subheader("üìä Fuente de Datos")
            data_source = st.radio(
                "Seleccionar fuente:",
                ["Datos Sint√©ticos", "Cargar CSV"],
                index=0
            )
            
            if data_source == "Datos Sint√©ticos":
                n_matches = st.slider(
                    "N√∫mero de partidos",
                    min_value=6,
                    max_value=15,
                    value=6,
                    step=1
                )
                generate_btn = st.button("üöÄ Ejecutar Simulaci√≥n Completa", type="primary")
            else:
                uploaded_file = st.file_uploader(
                    "Subir CSV con datos",
                    type=['csv'],
                    help="Columnas requeridas: home_attack, away_attack, home_defense, away_defense, odds_1, odds_X, odds_2"
                )
                generate_btn = uploaded_file is not None
            
            # Informaci√≥n del sistema
            with st.expander("‚ÑπÔ∏è Acerca del Sistema"):
                st.markdown("""
                **ACBE-S73 v2.0 - Caracter√≠sticas:**
                - ‚úÖ **Cobertura S73 completa** (2 errores en 6 partidos)
                - ‚úÖ **Reducci√≥n probabil√≠stica** por entrop√≠a
                - ‚úÖ **Kelly integrado** por columna y portafolio
                - ‚úÖ **Backtesting realista** con gesti√≥n de capital
                - ‚úÖ **An√°lisis de riesgo** profesional (VaR, CVaR, Sharpe)
                """)
            
            return {
                'bankroll': bankroll,
                'kelly_fraction': kelly_fraction,
                'max_exposure': max_exposure / 100,
                'monte_carlo_sims': monte_carlo_sims,
                'n_rounds': n_rounds,
                'data_source': data_source,
                'n_matches': n_matches if data_source == "Datos Sint√©ticos" else None,
                'uploaded_file': uploaded_file if data_source == "Cargar CSV" else None,
                'generate_btn': generate_btn
            }
    
    def render_acbe_analysis(self, probabilities: np.ndarray, 
                            odds_matrix: np.ndarray,
                            normalized_entropies: np.ndarray):
        """Renderiza an√°lisis ACBE completo."""
        st.header("üî¨ An√°lisis ACBE")
        
        # Calcular m√©tricas
        entropy = ACBEModel.calculate_entropy(probabilities)
        expected_value = InformationTheory.calculate_expected_value(probabilities, odds_matrix)
        
        # Clasificaci√≥n de partidos
        allowed_signs, classifications = InformationTheory.classify_matches_by_entropy(
            probabilities, normalized_entropies
        )
        
        # DataFrames para visualizaci√≥n
        n_matches = len(probabilities)
        
        df_acbe = pd.DataFrame({
            'Partido': range(1, n_matches + 1),
            'Clasificaci√≥n': classifications,
            'P(1)': probabilities[:, 0],
            'P(X)': probabilities[:, 1],
            'P(2)': probabilities[:, 2],
            'Entrop√≠a': entropy,
            'Entrop√≠a Norm.': normalized_entropies
        })
        
        df_odds = pd.DataFrame({
            'Partido': range(1, n_matches + 1),
            'Cuota 1': odds_matrix[:, 0],
            'Cuota X': odds_matrix[:, 1],
            'Cuota 2': odds_matrix[:, 2],
            'EV 1': expected_value[:, 0],
            'EV X': expected_value[:, 1],
            'EV 2': expected_value[:, 2],
            'Signos Permitidos': [str([SystemConfig.OUTCOME_LABELS[s] for s in signs]) 
                                 for signs in allowed_signs]
        })
        
        # Mostrar en columnas
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("üìä Probabilidades ACBE")
            st.dataframe(df_acbe.style.format({
                'P(1)': '{:.3f}',
                'P(X)': '{:.3f}',
                'P(2)': '{:.3f}',
                'Entrop√≠a': '{:.3f}',
                'Entrop√≠a Norm.': '{:.3f}'
            }), use_container_width=True)
        
        with col2:
            st.subheader("üí∞ Cuotas y Valor Esperado")
            st.dataframe(df_odds.style.format({
                'Cuota 1': '{:.2f}',
                'Cuota X': '{:.2f}',
                'Cuota 2': '{:.2f}',
                'EV 1': '{:.3f}',
                'EV X': '{:.3f}',
                'EV 2': '{:.3f}'
            }), use_container_width=True)
        
        # Visualizaciones
        self._render_acbe_visualizations(probabilities, entropy, normalized_entropies)
    
    def _render_acbe_visualizations(self, probabilities: np.ndarray,
                                   entropy: np.ndarray,
                                   normalized_entropies: np.ndarray):
        """Renderiza visualizaciones del an√°lisis ACBE."""
        n_matches = len(probabilities)
        
        # Gr√°fico de probabilidades
        fig_probs = go.Figure()
        for i, outcome in enumerate(['1', 'X', '2']):
            fig_probs.add_trace(go.Bar(
                x=list(range(1, n_matches + 1)),
                y=probabilities[:, i],
                name=outcome,
                marker_color=SystemConfig.OUTCOME_COLORS[i],
                text=[f'{p:.1%}' for p in probabilities[:, i]],
                textposition='auto'
            ))
        
        fig_probs.update_layout(
            title="Probabilidades ACBE por Partido",
            barmode='stack',
            xaxis_title="Partido",
            yaxis_title="Probabilidad",
            height=400
        )
        
        # Gr√°fico de entrop√≠a
        fig_entropy = go.Figure()
        fig_entropy.add_trace(go.Scatter(
            x=list(range(1, n_matches + 1)),
            y=normalized_entropies,
            mode='lines+markers',
            name='Entrop√≠a Normalizada',
            line=dict(color=SystemConfig.COLORS['primary'], width=3)
        ))
        
        # L√≠neas de umbral
        fig_entropy.add_hline(
            y=SystemConfig.STRONG_MATCH_THRESHOLD,
            line_dash="dash",
            line_color=SystemConfig.COLORS['success'],
            annotation_text="Fuerte"
        )
        fig_entropy.add_hline(
            y=SystemConfig.MEDIUM_MATCH_THRESHOLD,
            line_dash="dash", 
            line_color=SystemConfig.COLORS['warning'],
            annotation_text="Medio"
        )
        
        fig_entropy.update_layout(
            title="Clasificaci√≥n por Entrop√≠a",
            xaxis_title="Partido",
            yaxis_title="Entrop√≠a Normalizada",
            height=400,
            yaxis_range=[0, 1]
        )
        
        st.plotly_chart(fig_probs, use_container_width=True)
        st.plotly_chart(fig_entropy, use_container_width=True)
    
    def render_s73_system(self, probabilities: np.ndarray,
                         odds_matrix: np.ndarray,
                         normalized_entropies: np.ndarray,
                         bankroll: float):
        """Renderiza sistema S73 completo."""
        st.header("üßÆ Sistema Combinatorio S73")
        
        with st.spinner("Construyendo sistema S73 optimizado..."):
            # 1. Generar combinaciones pre-filtradas
            filtered_combo, filtered_probs = S73System.generate_prefiltered_combinations(
                probabilities, normalized_entropies
            )
            
            # 2. Construir sistema de cobertura
            s73_combo, s73_probs = S73System.build_s73_coverage_system(
                filtered_combo, filtered_probs
            )
            
            # 3. Calcular m√©tricas por columna
            n_columns = len(s73_combo)
            columns_data = []
            
            for idx, (combo, prob) in enumerate(zip(s73_combo, s73_probs), 1):
                # Calcular cuota conjunta
                combo_odds = S73System.calculate_combination_odds(combo, odds_matrix)
                
                # Calcular entrop√≠a promedio de la combinaci√≥n
                combo_entropy = np.mean([normalized_entropies[i] for i in range(6)])
                
                # Calcular Kelly para la columna
                kelly_stake = KellyCapitalManagement.calculate_column_kelly(
                    combo, prob, combo_odds, combo_entropy
                )
                
                columns_data.append({
                    'ID': idx,
                    'Combinaci√≥n': ''.join([SystemConfig.OUTCOME_LABELS[s] for s in combo]),
                    'Probabilidad': prob,
                    'Cuota': combo_odds,
                    'Valor Esperado': prob * combo_odds - 1,
                    'Entrop√≠a Prom.': combo_entropy,
                    'Kelly (%)': kelly_stake * 100,
                    'Inversi√≥n (‚Ç¨)': kelly_stake * bankroll
                })
            
            # Crear DataFrame
            columns_df = pd.DataFrame(columns_data)
            
            # 4. Normalizar stakes del portafolio
            kelly_stakes = np.array([d['Kelly (%)'] for d in columns_data]) / 100
            kelly_stakes = KellyCapitalManagement.normalize_portfolio_stakes(kelly_stakes)
            
            # Actualizar DataFrame con stakes normalizados
            for i, stake in enumerate(kelly_stakes):
                columns_df.at[i, 'Kelly (%)'] = stake * 100
                columns_df.at[i, 'Inversi√≥n (‚Ç¨)'] = stake * bankroll
        
        # Estad√≠sticas del sistema
        st.subheader("üìà Estad√≠sticas del Sistema S73")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Combinaciones Iniciales", len(filtered_combo))
        with col2:
            st.metric("Columnas S73 Finales", n_columns)
        with col3:
            total_exposure = np.sum(kelly_stakes) * 100
            st.metric("Exposici√≥n Total", f"{total_exposure:.1f}%")
        with col4:
            avg_prob = np.mean(s73_probs) * 100
            st.metric("Probabilidad Promedio", f"{avg_prob:.2f}%")
        
        # Mostrar columnas
        st.subheader("üìã Columnas del Sistema")
        
        display_df = columns_df.copy()
        display_df['Probabilidad'] = display_df['Probabilidad'].apply(lambda x: f'{x:.4%}')
        display_df['Cuota'] = display_df['Cuota'].apply(lambda x: f'{x:.2f}')
        display_df['Valor Esperado'] = display_df['Valor Esperado'].apply(lambda x: f'{x:.4f}')
        display_df['Entrop√≠a Prom.'] = display_df['Entrop√≠a Prom.'].apply(lambda x: f'{x:.3f}')
        display_df['Kelly (%)'] = display_df['Kelly (%)'].apply(lambda x: f'{x:.2f}%')
        display_df['Inversi√≥n (‚Ç¨)'] = display_df['Inversi√≥n (‚Ç¨)'].apply(lambda x: f'‚Ç¨{x:.2f}')
        
        st.dataframe(display_df, use_container_width=True, height=400)
        
        # Preparar resultados para backtesting
        s73_results = {
            'combinations': s73_combo,
            'probabilities': s73_probs,
            'kelly_stakes': kelly_stakes,
            'filtered_count': len(filtered_combo),
            'final_count': n_columns
        }
        
        return s73_results
    
    def render_backtest_results(self, backtest_results: Dict, config: Dict):
        """Renderiza resultados del backtesting."""
        st.header("üìà Resultados del Backtesting")
        
        metrics = backtest_results['final_metrics']
        
        # M√©tricas principales
        st.subheader("üìä M√©tricas de Rendimiento")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Bankroll Final", f"‚Ç¨{metrics['final_bankroll']:,.2f}")
            st.metric("Retorno Total", f"{metrics['total_return_pct']:.2f}%")
        with col2:
            st.metric("Sharpe Ratio", f"{metrics['sharpe_ratio']:.2f}")
            st.metric("CAGR", f"{metrics['cagr']:.2f}%")
        with col3:
            st.metric("Max Drawdown", f"{metrics['max_drawdown']:.2f}%")
            st.metric("Win Rate", f"{metrics['win_rate']:.2f}%")
        with col4:
            st.metric("Profit Factor", f"{metrics['profit_factor']:.2f}")
            st.metric("VaR 95%", f"‚Ç¨{metrics['var_95']:.2f}")
        
        # Gr√°ficos
        self._render_backtest_charts(backtest_results)
        
        # An√°lisis de riesgo
        self._render_risk_analysis(backtest_results, metrics)
    
    def _render_backtest_charts(self, backtest_results: Dict):
        """Renderiza gr√°ficos del backtesting."""
        # Curva de equity y drawdown
        fig_equity = make_subplots(specs=[[{"secondary_y": True}]])
        
        # Equity curve
        fig_equity.add_trace(
            go.Scatter(
                x=list(range(len(backtest_results['equity_curve']))),
                y=backtest_results['equity_curve'],
                name='Bankroll',
                line=dict(color=SystemConfig.COLORS['success'], width=3)
            ),
            secondary_y=False
        )
        
        # Drawdown
        fig_equity.add_trace(
            go.Scatter(
                x=list(range(len(backtest_results['drawdown_curve']))),
                y=backtest_results['drawdown_curve'],
                name='Drawdown',
                line=dict(color=SystemConfig.COLORS['danger'], width=2)
            ),
            secondary_y=True
        )
        
        fig_equity.update_layout(
            title="Evoluci√≥n del Bankroll y Drawdown",
            xaxis_title="Ronda",
            height=500
        )
        fig_equity.update_yaxes(title_text="Bankroll (‚Ç¨)", secondary_y=False)
        fig_equity.update_yaxes(title_text="Drawdown %", secondary_y=True)
        
        # Distribuci√≥n de retornos
        fig_returns = go.Figure()
        returns = backtest_results['all_returns']
        
        fig_returns.add_trace(go.Histogram(
            x=returns,
            nbinsx=50,
            name='Distribuci√≥n de Retornos',
            marker_color=SystemConfig.COLORS['info'],
            opacity=0.7
        ))
        
        # Estad√≠sticas en el gr√°fico
        mean_return = np.mean(returns)
        median_return = np.median(returns)
        
        fig_returns.add_vline(
            x=mean_return,
            line_dash="dash",
            line_color=SystemConfig.COLORS['primary'],
            annotation_text=f"Media: ‚Ç¨{mean_return:.2f}"
        )
        fig_returns.add_vline(
            x=median_return,
            line_dash="dot",
            line_color=SystemConfig.COLORS['secondary'],
            annotation_text=f"Mediana: ‚Ç¨{median_return:.2f}"
        )
        
        fig_returns.update_layout(
            title="Distribuci√≥n de Retornos por Ronda",
            xaxis_title="Retorno (‚Ç¨)",
            yaxis_title="Frecuencia",
            height=400
        )
        
        # Mostrar gr√°ficos
        col1, col2 = st.columns(2)
        with col1:
            st.plotly_chart(fig_equity, use_container_width=True)
        with col2:
            st.plotly_chart(fig_returns, use_container_width=True)
    
    def _render_risk_analysis(self, backtest_results: Dict, metrics: Dict):
        """Renderiza an√°lisis de riesgo detallado."""
        st.subheader("üîç An√°lisis de Riesgo Detallado")
        
        returns = backtest_results['all_returns']
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Calcular CVaR
            var_95 = np.percentile(returns, 5)
            cvar_95 = np.mean(returns[returns <= var_95])
            
            st.metric("CVaR 95%", f"‚Ç¨{cvar_95:.2f}")
            st.metric("Volatilidad (œÉ)", f"‚Ç¨{metrics['std_returns']:.2f}")
            st.metric("Ratio Sortino", 
                     f"{(np.mean(returns) / np.std(returns[returns < 0])):.2f}" 
                     if np.std(returns[returns < 0]) > 0 else "N/A")
        
        with col2:
            # Estad√≠sticas de colas
            positive_returns = returns[returns > 0]
            negative_returns = returns[returns <= 0]
            
            st.metric("Asimetr√≠a (Skewness)", f"{pd.Series(returns).skew():.3f}")
            st.metric("Curtosis", f"{pd.Series(returns).kurtosis():.3f}")
            st.metric("Ratio Ganancia/P√©rdida", 
                     f"{abs(np.mean(positive_returns)/np.mean(negative_returns)):.2f}"
                     if len(negative_returns) > 0 else "N/A")
    
    def render_executive_summary(self, s73_results: Dict, backtest_results: Dict, config: Dict):
        """Renderiza resumen ejecutivo del sistema."""
        st.header("üìã Resumen Ejecutivo")
        
        metrics = backtest_results['final_metrics']
        
        # Eficiencia del sistema
        st.subheader("üéØ Eficiencia del Sistema S73")
        
        efficiency_data = {
            'M√©trica': [
                'Reducci√≥n del Espacio',
                'Cobertura de Errores', 
                'Exposici√≥n Total',
                'Diversificaci√≥n'
            ],
            'Valor': [
                f"{s73_results['filtered_count']} ‚Üí {s73_results['final_count']}",
                f"{SystemConfig.HAMMING_DISTANCE_TARGET} errores",
                f"{np.sum(s73_results['kelly_stakes']) * 100:.1f}%",
                f"{len(set([tuple(c) for c in s73_results['combinations']]))} √∫nicas"
            ]
        }
        
        st.table(pd.DataFrame(efficiency_data))
        
        # Rentabilidad
        st.subheader("üìà Rentabilidad Esperada")
        
        profitability_data = {
            'M√©trica': ['ROI Total', 'Sharpe Ratio', 'Win Rate', 'Expectativa/Ronda'],
            'Valor': [
                f"{metrics['total_return_pct']:.2f}%",
                f"{metrics['sharpe_ratio']:.2f}",
                f"{metrics['win_rate']:.2f}%",
                f"‚Ç¨{np.mean(backtest_results['all_returns']):.2f}"
            ]
        }
        
        st.table(pd.DataFrame(profitability_data))
        
        # Recomendaciones
        st.subheader("üí° Recomendaciones de Gesti√≥n")
        
        total_exposure = np.sum(s73_results['kelly_stakes']) * 100
        
        if total_exposure > 20:
            exposure_status = "‚ö†Ô∏è ALTO"
            exposure_rec = "Reducir exposici√≥n a <15%"
        elif total_exposure > 10:
            exposure_status = "‚úÖ MODERADO" 
            exposure_rec = "Exposici√≥n adecuada"
        else:
            exposure_status = "‚úÖ BAJO"
            exposure_rec = "Podr√≠a aumentar exposici√≥n"
        
        if metrics['max_drawdown'] > 25:
            risk_status = "‚ö†Ô∏è ALTO"
            risk_rec = "Implementar stop-loss agresivo"
        elif metrics['max_drawdown'] > 15:
            risk_status = "‚ö†Ô∏è MODERADO"
            risk_rec = "Monitorear drawdown semanal"
        else:
            risk_status = "‚úÖ BAJO"
            risk_rec = "Riesgo bien controlado"
        
        recommendations = pd.DataFrame({
            '√Årea': ['Exposici√≥n', 'Riesgo', 'Diversificaci√≥n', 'Gesti√≥n'],
            'Estado': [exposure_status, risk_status, '‚úÖ ADECUADO', '‚úÖ IMPLEMENTADO'],
            'Recomendaci√≥n': [exposure_rec, risk_rec, 
                            f"{s73_results['final_count']} columnas bien diversificadas",
                            f"Kelly ajustado con l√≠mite {SystemConfig.KELLY_FRACTION_MAX*100:.0f}%"]
        })
        
        st.dataframe(recommendations, use_container_width=True, hide_index=True)
        
        # Conclusi√≥n final
        st.subheader("üéØ Conclusi√≥n del Sistema")
        
        roi = metrics['total_return_pct']
        sharpe = metrics['sharpe_ratio']
        
        if roi > 10 and sharpe > 1.5:
            conclusion = "EXCELENTE - Sistema altamente rentable con excelente perfil riesgo/retorno"
            color = SystemConfig.COLORS['success']
        elif roi > 5 and sharpe > 1.0:
            conclusion = "BUENO - Sistema rentable con gesti√≥n adecuada de riesgo"
            color = SystemConfig.COLORS['success']
        elif roi > 0:
            conclusion = "ACEPTABLE - Sistema positivo con margen de mejora"
            color = SystemConfig.COLORS['warning']
        else:
            conclusion = "MEJORABLE - Revisar configuraci√≥n del sistema"
            color = SystemConfig.COLORS['danger']
        
        st.markdown(f"""
        <div style="background-color:{color}20; padding:20px; border-radius:10px; border-left:5px solid {color};">
            <h4 style="color:{color};">{conclusion}</h4>
            <p><strong>Simulaciones realizadas:</strong> {config['n_rounds']} rondas √ó {config['monte_carlo_sims']:,} iteraciones Monte Carlo</p>
            <p><strong>Resultado final:</strong> ‚Ç¨{metrics['final_bankroll']:,.2f} ({roi:+.2f}%)</p>
            <p><strong>Calidad del sistema:</strong> Sharpe Ratio = {sharpe:.2f}, Max Drawdown = {metrics['max_drawdown']:.1f}%</p>
        </div>
        """, unsafe_allow_html=True)
    
    def run(self):
        """M√©todo principal de ejecuci√≥n de la aplicaci√≥n."""
        st.title("üéØ ACBE-S73 Quantum Betting Suite v2.0")
        st.markdown("""
        *Sistema profesional de optimizaci√≥n de portafolios de apuestas deportivas*  
        *Con cobertura S73 completa, gesti√≥n probabil√≠stica y Kelly integrado*
        """)
        
        # Renderizar sidebar y obtener configuraci√≥n
        config = self.render_sidebar()
        
        if not config['generate_btn']:
            st.info("üëà Configura los par√°metros en la sidebar y ejecuta la simulaci√≥n")
            return
        
        try:
            # Crear pesta√±as principales
            tab1, tab2, tab3, tab4 = st.tabs([
                "üìä An√°lisis ACBE", 
                "üßÆ Sistema S73", 
                "üìà Backtesting",
                "üìã Resumen"
            ])
            
            with st.spinner("üîÑ Procesando datos y ejecutando simulaciones..."):
                # Cargar/generar datos
                if config['data_source'] == "Datos Sint√©ticos":
                    matches_df, odds_df, probabilities = SyntheticDataGenerator.generate_complete_dataset(
                        config['n_matches']
                    )
                else:
                    # Cargar CSV personalizado
                    matches_df = pd.read_csv(config['uploaded_file'])
                    required_cols = ['home_attack', 'away_attack', 'home_defense', 'away_defense']
                    odds_cols = ['odds_1', 'odds_X', 'odds_2']
                    
                    if not all(col in matches_df.columns for col in required_cols + odds_cols):
                        st.error(f"‚ùå CSV debe contener: {required_cols + odds_cols}")
                        return
                    
                    odds_df = matches_df[odds_cols].copy()
                    odds_df.columns = ['odds_1', 'odds_X', 'odds_2']
                    matches_df = matches_df[required_cols].copy()
                    
                    # Calcular probabilidades ACBE
                    attack_strengths = matches_df[['home_attack', 'away_attack']].values
                    defense_strengths = matches_df[['home_defense', 'away_defense']].values
                    
                    lambda_home, lambda_away = ACBEModel.gamma_poisson_bayesian(
                        attack_strengths, defense_strengths
                    )
                    probabilities = ACBEModel.vectorized_poisson_simulation(lambda_home, lambda_away)
                
                odds_matrix = odds_df.values
                
                # Calcular entrop√≠as
                entropy = ACBEModel.calculate_entropy(probabilities)
                normalized_entropy = ACBEModel.normalize_entropy(entropy)
                
                # Actualizar configuraci√≥n de exposici√≥n m√°xima
                SystemConfig.MAX_PORTFOLIO_EXPOSURE = config['max_exposure']
            
            # Pesta√±a 1: An√°lisis ACBE
            with tab1:
                self.render_acbe_analysis(probabilities, odds_matrix, normalized_entropy)
            
            # Verificar que hay al menos 6 partidos para S73
            if len(probabilities) < 6:
                st.warning("‚ö†Ô∏è Se necesitan al menos 6 partidos para el sistema S73")
                return
            
            # Usar solo primeros 6 partidos para S73 (sistema cl√°sico)
            probs_6 = probabilities[:6, :]
            odds_6 = odds_matrix[:6, :]
            entropy_6 = normalized_entropy[:6]
            
            # Pesta√±a 2: Sistema S73
            with tab2:
                s73_results = self.render_s73_system(probs_6, odds_6, entropy_6, config['bankroll'])
            
            # Pesta√±a 3: Backtesting
            with tab3:
                # Ejecutar backtesting
                backtester = VectorizedBacktester(initial_bankroll=config['bankroll'])
                
                with st.spinner("Ejecutando backtesting completo..."):
                    backtest_results = backtester.run_backtest(
                        probs_6, odds_6, entropy_6,
                        s73_results,
                        n_rounds=config['n_rounds'],
                        n_sims_per_round=config['monte_carlo_sims'],
                        kelly_fraction=config['kelly_fraction']
                    )
                
                self.render_backtest_results(backtest_results, config)
            
            # Pesta√±a 4: Resumen ejecutivo
            with tab4:
                self.render_executive_summary(s73_results, backtest_results, config)
                
        except Exception as e:
            st.error(f"‚ùå Error en la ejecuci√≥n: {str(e)}")
            st.exception(e)

# ============================================================================
# EJECUCI√ìN PRINCIPAL
# ============================================================================

if __name__ == "__main__":
    app = ACBEApp()
    app.run()
